---
title: 'WCSS 2019: <br>Exploring Twitter Trolls'
author: "Benjamin Ortiz Ulloa"
date: "2/5/2019"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidytext)
library(stm)
library(igraph)
```

# Introduction to 2016 Russian Twitter Troll Dataset

## [According to the US Office of the Director of National Intelligence](https://www.dni.gov/files/documents/ICA_2017_01.pdf)

- Russian President Vladimir Putin ordered an influence campaign in 2016 aimed at the US presidential election. Russia’s goals were to undermine public faith in the US democratic process, denigrate Secretary Clinton, and harm her electability and potential presidency.
- Moscow's influence campaign followed a Russian messaging strategy that blends covert intelligence operations—such as cyber activity—with overt efforts by Russian Government agencies, state-funded media, third-party intermediaries, and paid social media users or "trolls."
- The House Intelligence released a list of 2,752 false Twitter accounts believed to be operated by a known Russian troll factory – the Internet Research Agency.

<div class="notes">
-In January 2017, the ofice of the director of national intelligence released a report claiming that Russia interfered with the the 2016 US election with an intent to dissuade voters from voting for Hillary Clinton and undermine public faith in the US democratic proces. 
-A russian company, the Internet Research Agency, was named as a company that tried to achieve this goal with the use of twitter trolls.
</div>

## Recovered Twitter Data

- The trolls were removed from Twitter once they were identified.
- NBC News was able to recover the tweets posted by the trolls and made the data public.
- [NBC collaborated with Neo4j to conduct network analysis and answer the question - how did these trolls succeed?](https://neo4j.com/blog/story-behind-russian-twitter-trolls/)
- A subset of this data can be found on [Kaggle](https://www.kaggle.com/vikasg/russian-troll-tweets)

<div class="notes">
-Thanks to NBC, Data about the trolls' tweets and profiles are now public for people to explore. 
</div>

## Troll Personas

**Three types of Profiles:**

- The Typical American Citizen
- The Local Media Outlet
- The Local Political Party

**Three main sentiments:**

- Focus on Right Wing Politics (Positive)
- Focus on Left Wing Politics (Negative)
- Focus on Black Lives Matter (Positive)

<div class="notes">
-The goal of these accounts was to blend into the US twitter ecosystem as "one of us".
-The idea people are more likely to agree with a troll's claims if their personas match.
-Republicans are more likely to agree with republican style trolls and those who are part of the black lives matter movement are more likely to agree with trolls that claim to share their sentiment.
</div>

## NBC's and Neo4j's Analysis

```{r pressure, echo=FALSE,  out.height = '450px', out.width = '300px'}
knitr::include_graphics("russian-troll-twitter-network-pagerank-graph-algorithm.png")
```

## Internal Workings

- There were only a handful of trolls that created their own content
- A majority of the trolls simply retweeted others in order to amplify their message
<div class="notes">
-These trolls were able to create an amplification network. 
-It was more important to amplify a single trolls tweet than it was to create a large number of original content creators. 
</div>

# Reproduce these results in R & igraph

## How to make a graph: Edge List

```{r, echo=F, message=F}
tweets <- readr::read_csv('../../igraph-data-days-texas-2019/russian-troll-tweets/tweets.csv')

retweet_network <- tweets  %>% 
  dplyr::select(user_key, text) %>%
  dplyr::filter(stringr::str_detect(text, '^RT\\s')) %>%
  dplyr::mutate(retweeted = stringr::str_extract(text, '(?<=@)[^:]+(?=:)') %>%
                  stringr::str_to_lower()) %>%
  dplyr::filter(!is.na(retweeted)) %>%
  dplyr::select(user_key, retweeted, text) %>%
  dplyr::mutate(text = stringr::str_replace_all(text, "\\r|\\n", '') ) %>%
  dplyr::distinct()

retweet_network %>%
  head() %>%
  knitr::kable()
```

<div class="notes">
-one of R's native data structures is a data frame - a table like structure
-if we want to create a graph, we need to have a data frame in which the first two columns of a data frame represent the nodes the edges are connecting. 
</div>

## How to make a graph: Aggregation

```{r, echo = F}
filter_n <- 5

retweet_network_wt <- retweet_network %>%
  dplyr::count(user_key, retweeted, sort = T) %>%
  dplyr::filter(n >= filter_n) 

retweet_network_wt %>%
  head() %>%
  knitr::kable()
```

<div class="notes">
-for now, we won't focus on content, but the number of retweets.
-R has a package called dplyr that makes aggregation painless.
-any subsequent column after the first two are stored as edge attributes. So we can consider n a weight of the edge. 
</div>

## Visualize the Graph

```{r}
g_rtwt <- igraph::graph_from_data_frame(retweet_network_wt, T) %>%
  {V(.)$pr <- igraph::page_rank(., directed = T)$vector; .} 

set.seed(4321)
g_rtwt %>%
  plot(
    vertex.size = 2,
    vertex.label = '',
    edge.arrow.size = .05,
    edge.width = .25,
    asp = 0, 
    main = stringr::str_glue('Troll Retweet Network:\n {vcount(.)} Trolls and {ecount(.)} Connections'),
    sub = stringr::str_glue('Connections of less than {filter_n} retweets were removed.'))
```

## Calculate (Directed) PageRank

```{r, echo = F}
set.seed(4321)
g_rtwt %>%
  plot(
    vertex.size = V(.)$pr/max(V(.)$pr) * 5+ 1,
    vertex.label = '',
    edge.arrow.size = .05,
    edge.width = .25,
    asp = 0, 
    main = stringr::str_glue('Troll Retweet Network:\n {vcount(.)} Trolls and {ecount(.)} Connections'),
    sub = stringr::str_glue("Connections of less than {filter_n} retweets were removed.\nSize corresponds to troll's page rank"))
```

## Analyze Top PageRanked Trolls
```{r, echo =F}

original_tweets <- tweets %>%
  dplyr::filter(user_key %in% retweet_network$retweeted)  %>%
  dplyr::select(user_key, text) %>%
  dplyr::filter(!stringr::str_detect(text, '^RT @')) %>%
  dplyr::distinct()

original_tweets_ag <- original_tweets %>%
  dplyr::count(user_key) %>%
  dplyr::rename(OriginalTweets = n)

tweets_ag <- tweets %>%
  dplyr::select(user_key, text) %>%
  dplyr::distinct() %>%
  dplyr::count(user_key) %>%
  dplyr::rename(AllTweets = n)

g_rtwt %>%
  {igraph::V(.)$InStrength <- igraph::strength(., mode = 'in', weights = E(.)$n); .} %>%
  {igraph::V(.)$OutStrength <- igraph::strength(., mode = 'out', weights = E(.)$n); .} %>%
  igraph::as_data_frame('vertices') %>%
  dplyr::arrange(dplyr::desc(pr)) %>%
  head(10) %>%
  dplyr::select(name, PageRank = pr, InStrength, OutStrength) %>%
  dplyr::left_join(original_tweets_ag, by = c('name' = 'user_key')) %>%
  dplyr::left_join(tweets_ag, by = c('name' = 'user_key')) %>%
  knitr::kable()
```

## Trolls Retweeted Non-Trolls

Some twitter handles were not counted in the data because they were not among the list of twitter trolls.

- **rt_com** and **rt_america** are part of the [RT Network](https://en.wikipedia.org/wiki/RT_(TV_network)). A moscow based television network that used to be called "Russia Today"
- **chiefplan1**, **joyannreid**, **owillis** are left-wing news personalities.
- **spiegelonline** is a german news website

## Remove Non-Trolls and Recalculate

```{r, echo = F, message = F}

pr <- igraph::page_rank(g_rtwt)$vector
igraph::V(g_rtwt)$PageRank <- pr

vertex_df <- igraph::as_data_frame(g_rtwt, 'vertices') %>%
  dplyr::arrange(desc(PageRank))

edges_df <- igraph::as_data_frame(g_rtwt, 'edges')
  
total_tweets <- tweets %>%
  dplyr::select(user_key, text) %>%
  dplyr::count(user_key) %>%
  dplyr::rename(TotalTweets = n)

vertex_df <- dplyr::left_join(vertex_df, total_tweets, by = c('name' = 'user_key'))
g_rtwt_troll <-igraph::graph_from_data_frame(edges_df, T, vertex_df) %>%
  {. - igraph::V(.)[is.na(TotalTweets)]} %>%
  {. - igraph::V(.)[igraph::degree(.) == 0]} %>%#remove unconnected nodes
  {set.seed(4321); l <- igraph::layout_nicely(.); V(.)$x = l[,1]; V(.)$y = l[,2]; .} %>%
  {V(.)$PageRank <- igraph::page_rank(.)$vector; .} %>%
  {V(.)$InStrength <- igraph::strength(., mode = 'in', weights = E(.)$n); .} %>%
  {V(.)$OutStrength <- igraph::strength(., mode = 'out', weight = E(.)$n); .} %>%
  {V(.)$size <- igraph::V(.)$PageRank/max(igraph::V(.)$PageRank)* 5 + 3; .} %>%
  {V(.)$label <- ''; .} %>%
  {E(.)$arrow.size = .25; .} %>%
  {E(.)$width = .1; .} %>%
  {.$asp = 0; .}

set.seed(4321)
plot(g_rtwt_troll)
```


## Analyze Cleaned Network

```{r, echo = F}
g_rtwt_troll %>%
  igraph::as_data_frame('vertices') %>%
  dplyr::arrange(dplyr::desc(PageRank)) %>%
  head(10) %>%
  dplyr::select(name, PageRank, InStrength, OutStrength,
                TotalTweets) %>%
  knitr::kable()
```

## Community Detection (Walktrap)

```{r, echo = F}
set.seed(4321)
troll_community <- igraph::walktrap.community(g_rtwt_troll)
troll_groups <- igraph::groups(troll_community)
V(g_rtwt_troll)$community <- troll_community$membership
community_pal <- scales::brewer_pal('qual')(length(troll_groups))
names(community_pal) <- as.character(1:length(community_pal))
V(g_rtwt_troll)$color <- purrr::map_chr(V(g_rtwt_troll)$community, ~community_pal[.x])
plot(g_rtwt_troll)
```

## What Hashtags do these groups use?

```{r}
tweets_w_hashtags <- tweets %>%
  dplyr::select(user_key, hashtags) %>%
  dplyr::filter(hashtags != '[]') 

community_hashtags <- purrr::map(troll_groups, function(x){
  tweets_w_hashtags %>%
    dplyr::filter(user_key %in% x) %>%
    .$hashtags %>%
    purrr::map(~jsonlite::fromJSON(.x)) %>%
    unlist() %>%
    table() %>%
    sort(T) %>%
    tibble::enframe('hashtag', 'count') %>%
    head(10)
}) %>%
  tibble::enframe('community', 'data') %>%
  tidyr::unnest() 

community_hashtags %>%
  dplyr::mutate(hashtag = purrr::map2_chr(hashtag, community, ~paste0(paste0(rep(' ', as.numeric(.y)), collapse = ''), .x))) %>%
  dplyr::mutate(hashtag = factor(hashtag, unique(hashtag))) %>%
  ggplot2::ggplot(ggplot2::aes(x = hashtag, y = count, fill = community)) +
  ggplot2::geom_col(color = 'black') +
  ggplot2::facet_wrap(~community, scales = 'free') +
  ggplot2::scale_fill_manual(values = community_pal) +
  ggplot2::coord_flip()+
  ggplot2::theme_bw() +
  ggplot2::theme(legend.position="none") +
  ggplot2::labs(
    x = ''
  )
```

# Explore the usage of hashtags

## Create a bipartite graph

```{r, echo = F}
tweet_hashtag <- tweets %>% 
  dplyr::filter(hashtags != '[]') %>% #this represents a tweet with no hashtags
  dplyr::mutate(hashtags = purrr::map(hashtags, jsonlite::fromJSON)) %>% #the stored info is a json file
  dplyr::select(user_key, hashtags, text) %>% 
  tidyr::unnest() 

head(tweet_hashtag) %>%
  dplyr::select(user_key, hashtags) %>%
  knitr::kable()
```

## Aggregate Bipartite

```{r, echo = F}
tweet_hashtag_edges <- tweet_hashtag %>%
  dplyr::select(-text) %>%
  dplyr::count(user_key, hashtags, sort = T) %>% #aggregatign user-hashtag occurances
  dplyr::rename(weight = n) %>%
  dplyr::mutate(type = 'used_hashtag',
         user_key = paste0('@', user_key), #prevent duplicate node names
         hashtags = paste0('#', hashtags) %>% tolower() #prevent duplicate node names
         ) 

head(tweet_hashtag_edges) %>%
  knitr::kable()
```

## Create Graph

```{r, echo = F}
tweet_hashtag_nodes <- dplyr::bind_rows(
  tibble::tibble(
    label = tweet_hashtag_edges$hashtags %>% unique(),
    type = 'hashtag',
    color = 'lightgrey',
    size = 3
  ),
    tibble::tibble(
    label = tweet_hashtag_edges$user_key %>% unique(),
    type = 'user',
    color = 'purple',
    size = 3
  )
)

tweet_hashtag_g <- tweet_hashtag_edges %>%
  graph_from_data_frame(vertices = tweet_hashtag_nodes)

filter_n <- 6

tweet_hashtag_g_filtered <- tweet_hashtag_g %>%
  {. - E(.)[weight < filter_n]} %>%
  {. - V(.)[degree(.) == 0]} %>%
  {.$asp <- 0; .} %>%
  {E(.)$width <- .1; .}

tweet_hashtag_g_filtered %>%
  {set.seed(4321); .$layout <- igraph::layout.bipartite(., type = V(.)$type == 'hashtag'); .} %>%
  plot( 
     vertex.label = '',
     edge.arrow.mode = '-',
     main = stringr::str_glue("Troll - Hashtag Bipartite\n{V(.)[type == 'user'] %>% length()} Trolls and {V(.)[type == 'hashtag'] %>% length()} Hashtags"),
     sub = stringr::str_glue("Connections where Trolls used a hashtag less than {filter_n} times were removed")
     )
```

## Indirect User Connections

```{r, echo = F, message = F, warning= F}
tweet_hashtag_g_filtered %>%
  {
    V(.)$type <- V(.)$type == 'user'; #boolean type is necessary for bipartite projection
    V(.)$degree <- degree(.);
    V(.)$weighted_degree <- strength(.);
    .
  } %>%
  igraph::bipartite_projection() %>%
  {
    . <- purrr::map(., function(x){
      V(x)$component <-igraph::components(x)$membership;
      return(x)
    })
    hashtag_g <<- .$proj1; #projection 1 is type FALSE
    user_g <<- .$proj2; #projection 2 is type TRUE
  }

set.seed(4321)
l <- layout_nicely(user_g)
V(user_g)$x <- l[,1]
V(user_g)$y <- l[,2]
plot(user_g, vertex.size = 3, vertex.label = '')

```

## Indirect Hashtag Connections

```{r, echo = F}

set.seed(4321)
l <- layout_nicely(hashtag_g)
V(hashtag_g)$x <- l[,1]
V(hashtag_g)$y <- l[,2]
plot(hashtag_g, vertex.size = 3, vertex.label = '')
```



## Examine largest component

```{r, echo = F}
hashtag_g_components <- igraph::components(hashtag_g)

largestComponent <- hashtag_g_components %>%
  igraph::groups() %>%
  {
    maxL <- max(purrr::map_dbl(., length));
    .[purrr::map_lgl(., function(x){length(x) == maxL})] %>%
      unlist()
  } %>%
  {hashtag_g - igraph::V(hashtag_g)[!name %in% .]}
  

plot(largestComponent, vertex.size = 3, vertex.label = '', edge.width = .1)
```

## Community Detection and PageRank

```{r, echo =F}
hashtag_community <- igraph::walktrap.community(largestComponent)
hashtag_groups <- igraph::groups(hashtag_community)
V(largestComponent)$community <- hashtag_community$membership
V(largestComponent)$PageRank <- page.rank(largestComponent)$vector

hashtag_pal <- scales::brewer_pal('qual')(length(hashtag_groups))
names(hashtag_pal) <- as.character(1:length(hashtag_pal))
V(largestComponent)$color <- purrr::map_chr(V(largestComponent)$community, ~hashtag_pal[.x])


largestComponent <- largestComponent %>%
  {
    tmp <- as_data_frame(., 'both');
    tmp$vertices <- dplyr::arrange(tmp$vertices, PageRank);
    igraph::graph_from_data_frame(tmp$edges, F, tmp$vertices)
  }

largestComponent %>%
  plot(
    vertex.label= '',
    vertex.size = V(.)$PageRank/max(V(.)$PageRank) * 5 + 2,
    edge.width = .1,
    asp = 0
  )
```

## Sample of Hashtags

```{r, echo = F}

largestComponent %>%
  igraph::as_data_frame('vertices') %>%
  dplyr::group_by(community) %>%
  dplyr::top_n(10, PageRank) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(name = purrr::map2_chr(name, community, ~paste0(paste0(rep(' ', as.numeric(.y)), collapse = ''), .x))) %>%
  dplyr::mutate(name = factor(name, unique(name))) %>%
  ggplot2::ggplot(ggplot2::aes(x = name, y = PageRank, fill = as.character(community))) +
  ggplot2::geom_col(color= 'black') +
  ggplot2::facet_wrap(~community, scales = 'free') +
  ggplot2::scale_fill_manual(values = hashtag_pal) +
  ggplot2::coord_flip()+
  ggplot2::theme_bw() +
  ggplot2::theme(legend.position="none")
```

## How do these groups interact?

```{r}
largestComponent_summary <- largestComponent %>%
  {
    E(.)$tailCommunity <- tail_of(., E(.))$community; #store node information in edges 
    E(.)$headCommunity <- head_of(., E(.))$community; #to refrence later
    .
  } %>%
  igraph::as_data_frame('both') %>%
  {
    el <- .$edges %>%
      dplyr::filter(tailCommunity != headCommunity) %>%
      #1 - 6 is same as 6 - 1
      dplyr::mutate(
        tail = purrr::map2_dbl(tailCommunity, headCommunity, min) %>% round %>% as.character(),
        head = purrr::map2_dbl(tailCommunity, headCommunity, max) %>% round %>% as.character()
      ) %>%
      dplyr::group_by(tail, head) %>%
      tidyr::nest() %>%
      dplyr::mutate(data = purrr::map(data, function(x){
        top_hashes <- x %>%
          dplyr::arrange(dplyr::desc(weight)) %>%
          head(3) %>%
          {paste(.$from, .$to, sep = ' | ', collapse = '\n')}

        if(x$tailCommunity[1] %in% c(4, 1) & x$headCommunity[1] %in% c(4,1)){
          top_hashes <- paste('\n\n\n\n\n\n', top_hashes)
        }
        
        if(x$tailCommunity[1] %in% c(5,4) & x$headCommunity[1] %in% c(5,4)) {
          top_hashes <- paste(top_hashes, '\n\n\n\n\n\n\n\n')
        }
       
         
        

        tibble::tibble(
          top_hashes,
          sum_weight = sum(x$weight),
          ave_weight = mean(x$weight),
          count = nrow(x)
        )
      })) %>%
      tidyr::unnest()

    nl <- .$vertices %>%
      dplyr::mutate(community = as.character(community)) %>%
      dplyr::group_by(community) %>%
      tidyr::nest() %>%
      dplyr::mutate(top_hashes = purrr::map_chr(data, function(x){
        x %>%
          head %>%
          .$name %>%
          paste(collapse = '\n') %>%
          stringr::str_replace_all('hashtag_', '')
      })) 
    # %>%
    #   dplyr::mutate(x = purrr::map_dbl(data, function(x){
    #     mean(x$x)
    #   })) %>%
    #   dplyr::mutate(y = purrr::map_dbl(data, function(x){
    #     mean(x$y)
    #   }))

    set.seed(1)
    igraph::graph_from_data_frame(el, F, nl) %>%
      {
        l <- igraph::layout_nicely(.) #store layout information in vertices
        V(.)$x <- l[,1]
        V(.)$y <- l[,2]
        .
      }
  }


largestComponent_summary %>% 
  plot(vertex.color = purrr::map_chr(V(.)$name, function(x){hashtag_pal[x]}), asp = 0)
```


## Community Hashtags

```{r, echo = F}
largestComponent_summary %>%
  plot(
    vertex.label = V(.)$top_hashes,
    vertex.label.cex = .5,
    vertex.size = 0, 
    vertex.shape = 'none',
    asp = 0) 
```

## Hashtags Connecting Communities

```{r, echo = F}
largestComponent_summary %>%
  {. - V(.)[degree(.) == 0]} %>%
  plot(
    edge.label = E(.)$top_hashes,
    edge.label.cex = .5,
    vertex.size = 1,
    vertex.shape = 'none',
    vertex.label = '',
    asp = 0
  )
```

# Using Topic Models

## Our Bipartite Graph

```{r, echo = F}
th_bi <- tweet_hashtag_edges %>%
  dplyr::filter(hashtags %in% igraph::V(largestComponent)$name)  %>%
  dplyr::filter(user_key %in% igraph::V(tweet_hashtag_g_filtered)$name) %>%
  dplyr::select(-type)
                
head(th_bi) %>%
  knitr::kable()
```

## Our Bipartite graph as a matrix

**Also known as a Document Term Matrix**

```{r, echo = F}

tweets_sparse_hash <- th_bi %>%
  cast_sparse(user_key, hashtags, weight)

tweets_sparse_hash[1:10, 1:5] 
```

## Create a Topic Model

```{r, echo = F}
# set.seed(4321)
# topic_model_hash <- stm::stm(tweets_sparse_hash, K = 8,
#                              verbose = FALSE, init.type = "Spectral")
# readr::write_rds(topic_model_hash, 'twitter_troll_topic_model_8.rds')

topic_model_hash <- readr::read_rds("twitter_troll_topic_model_8.rds")

td_beta_hash <- tidy(topic_model_hash)

td_beta_hash %>%
  dplyr::group_by(topic) %>%
  dplyr::top_n(5, beta) %>%
  dplyr::ungroup() %>%
  dplyr::arrange(dplyr::desc(beta)) %>%
  dplyr::mutate(term = purrr::map2_chr(term, topic, ~paste0(paste0(rep(' ', as.numeric(.y)), collapse = ''), .x))) %>%
  dplyr::mutate(term = factor(term, unique(term))) %>%
  dplyr::mutate(topic = paste0("Topic ", topic)) %>%
  ggplot2::ggplot(ggplot2::aes(term, beta, fill = as.factor(topic))) +
  ggplot2::geom_col(alpha = 0.8, show.legend = FALSE, color = 'black') +
  ggplot2::facet_wrap(~ topic, scales = "free") +
  ggplot2::coord_flip() +
  ggplot2::labs(x = NULL, y = expression(beta),
       title = "Grouping of Hashtags: Highest word probabilities for each topic",
       subtitle = "Different words are associated with different topics") +
  ggplot2::scale_fill_brewer(type = 'qual') +
  ggplot2::theme_bw()
```

## Label Hashtag with Greatest Beta
```{r, echo = F}
markedTopic<- td_beta_hash %>%
  dplyr::group_by(term) %>%
  dplyr::top_n(1, wt = beta) %>%
  dplyr::select(term, topic, beta) 

markedTopic %>%
  head %>%
  knitr::kable()
```

## Let's color by topics
```{r, echo = F}
topicLargestComponent <- largestComponent %>%
  igraph::as_data_frame('both') %>%
  {
    .$vertices <- dplyr::left_join(.$vertices, markedTopic, by = c('name' = 'term')) %>%
      dplyr::mutate(color = purrr::map_chr(topic, ~hashtag_pal[.x]));
    
    igraph::graph_from_data_frame(.$edges, F, .$vertices)
  }

plot(topicLargestComponent, vertex.label = '', asp = 0, vertex.size = 3, edge.width = .1)
```

# Resources to learn more

## [Tidyverse: Data Cleaning + Visualization](https://r4ds.had.co.nz)

```{r echo=FALSE,  out.height = '450px'}
knitr::include_graphics('r4ds.png')
```

## [Purrr: Iteration Helpers](https://jennybc.github.io/purrr-tutorial/)

```{r echo=FALSE,  out.height = '450px'}
knitr::include_graphics('purrr.png')
```

## [Tidy Text Mining](https://www.tidytextmining.com)

```{r echo=FALSE,  out.height = '450px', out.width = '300px'}
knitr::include_graphics('tidytext.png')
```

## [Visualizing Graphs: My Hero](http://kateto.net/tutorials/)

```{r echo=FALSE,  out.height = '450px'}
knitr::include_graphics('katyaognyanova.png')
```

## [Code to replicate](https://github.com/benjaminortizulloa/wwcs2019)

```{r echo=FALSE,  out.height = '450px'}
knitr::include_graphics('wwcs2019.png')
```
